\documentclass[12pt]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{pdflscape}
\usepackage[margin=2cm, left=3cm]{geometry}
\usepackage{color}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tocbasic}
\usepackage{fancyhdr}
\usepackage{float} 
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage[english, ngerman]{babel}
\usepackage{hyperref}
\usepackage{adjustbox}
\usepackage{color, colortbl}
\usepackage{array}
\usepackage[
    backend=biber,		
    bibwarn=true,
    bibencoding=utf8,	% wenn .bib in utf8, sonst ascii
    sortlocale=de_DE,
    style=numeric-comp,
]{biblatex}
\usepackage{csquotes}

\addbibresource{bibliographie.bib}

\selectlanguage{ngerman}

\hypersetup{%
    colorlinks=true, 		% Aktivieren von farbigen Links im Dokument
    linkcolor=black, 	    % Farbe festlegen
    citecolor=black,
    filecolor=black,
    menucolor=black,
    urlcolor=black,
    linktoc=all,            % Seitenzahlen und Text klickbar
    bookmarksnumbered=true 	% Überschriftsnummerierung im PDF Inhalt anzeigen.
}

\newcommand\todo[1]{\textit{\textcolor{red}{\\TODO: #1}}}

\DeclareNewTOC[%
 forcenames,
 type=formel,
 name={Formel},%
 listname={Formelverzeichnis}
]{for}
\newcommand*{\formelentry}[1]{%
     \addcontentsline{for}{formel}{\protect\numberline{\theequation} #1}%
    }



\title{Master Autonomes Fahren - Mathematik Zusammenfassung}
\author{Marcel Wagner}
\date{\today}

\definecolor{Gray}{gray}{0.9}
\definecolor{LightCyan}{rgb}{0.88,1,1}
\newcolumntype{x}{>{\columncolor{LightCyan}}l}


\begin{document}
\pagenumbering{Roman}
\maketitle
\tableofcontents
%\newpage
%\listoffigures
%\listoffigures
%\listofformels
\newpage
\pagenumbering{arabic}
\setcounter{page}{1}
\section{Mathematische Symbole}
\subsection{Mengen}
\begin{tabular}{p{0.1\textwidth}|p{0.2\textwidth}|p{0.6\textwidth}}
	Symbol & Verwendung & Bedeutung\\
	\hline
	$\in$ & $\omega\quad\in\quad\Omega$ & Element ($\omega$ ist in $\Omega$ enthalten) \\
	$\cap$ & $A\quad\cap\quad B$ & Disjunkt (Kein Teil von A ist ein Teil von B) \\
	$\cup$ & $A\quad\cup\quad B$ & Kunjunktion (Ein Teil von A ist ein Teil von B)\\
	$\subseteq$ & $A\quad\subseteq\quad B$ & Teilmenge (A ist eine Teilmenge von B)\\
	$\setminus$ & $A\quad\setminus\quad B$ & Differenz (Differenz der mengen A und B)\\
	$^\mathrm{C}$ & $A^\mathrm{C}$ & Komplement (Differenz des Universums (kann eine\newline größere Menge sein) und der Teilmenge)\\
	$\mathbb{N}$ & Natürliche Zahlen & Positive Ganze Zahlen ohne Null (1,2,3,...)\\
	$\mathbb{Z}$ & Ganze Zahlen & Ganze Zahlen (...,-2,-1,0,1,2,...)\\
	$\mathbb{Q}$ & Rationale Zahlen & $z\cdot \frac{1}{x}$ mit $z,x \in \mathbb{Z}$\\
	$\mathbb{R}$ & Reelle Zahlen & Erweiterung der Rationalen Zahlen durch diejenigen\newline Zahlen welche sich nicht durch Brüche darstellen\newline lassen (z.B.$\sqrt{2}, \pi$)\\
	$\mathbb{C}$ & Komplexe Zahlen & $a+bi$ mit $a,b\in \mathbb{R}$ und $i^2 = -1$\\
\end{tabular}

\section{Statistik}
\subsection{Arithmetisches Mittel}
\begin{equation*}
	\overline{x} := \frac{x_1 + ... + x_n}{n} = \frac{1}{n}\sum_{i=1}^{n}{x_i}
\end{equation*}
\subsection{Mittlerer Abstand}
Der mittlere Abstand wird nicht sehr häufig verwendet, da das Rechnen mit Beträgen sehr mühsam ist. Die Varianz (durchschnittliche quadratische Abweichung) eignet sich besser.
\begin{equation*}
	\frac{1}{n}\sum_{i=1}^{n}{|x_i-\overline{x}|}
\end{equation*}
\subsection{Varianz}
\begin{equation*}
	s_x^2= \frac{1}{n-1}\sum_{i=1}^n{(x_i-\overline{x})^2}
\end{equation*}
\subsection{Standartabweichung}
\begin{equation*}
	s_x = \sqrt{s_x^2}
\end{equation*}
\subsection{Kovarianz}
\begin{equation*}
	y_{xy}:=\frac{1}{n-1}\sum_{i=1}^n(x_i-\overline{x})(y_i-\overline{y})
\end{equation*}
\subsection{Korrelationskoeffizient}
\begin{equation*}
	r_{xy}:=\frac{s_{xy}}{s_x\cdot s_y}
\end{equation*}
\subsection{Regressionsgerade}
\begin{equation*}
	y = a + bx
\end{equation*}
\begin{equation*}
	b = \frac{s_{xy}}{s_x^2}
\end{equation*}
\begin{equation*}
	a = \overline{y} - b\overline{x}
\end{equation*}
\subsection{Bestimmtheitsmaß}
\begin{equation*}
	R^2 = \frac{\sum_{i=1}^n (\hat{y}_i-\overline{y})^2}{\sum_{i=1}^n (y_i-\overline{y})^2} = \frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{\sum_{i=1}^n (y_i-\overline{y})^2}
\end{equation*}
mit Arithmetischem Mittel $\overline{y}$ und Ausgleichsgerade $\hat{y}_i = y(x_i) = a+bx_i$.
\begin{equation*}
	R^2 = r_{xy}^2
\end{equation*}

\section{Wahrscheinlichkeitsrechnung}
\subsection{Fakultät}
\begin{equation*}
	n! = n \cdot (n-1) \cdot \dotsc \cdot 2 \cdot 1 
\end{equation*}
\subsection{Binomialkoeffizient}
\begin{equation*}
	{n \choose k} = \frac{n!}{k!\cdot(n-k)!}
\end{equation*}
\subsection{Kugeln Ziehen}
\begin{tabular}{c|c|c}
	 & mit Reihenfolge & ohne Reihenfolge 
	 \\\hline
	 mit Zurücklegen & $n^k$ & ${n+k-1 \choose k}$
	 \\\hline
	 ohne Zurücklegen & $\frac{n!}{(n-k)!}$ & ${n \choose k}$
\end{tabular}
\subsection{Menge}
Unter einer Menge verstehen wir die Zusammenfassung unterscheidbarer Elemente zu einer Gesamtheit.
\subsubsection{Gleichheit}
$A = B:\Leftrightarrow$ $A$ und $B$ besitzen die gleichen Elemente.
\subsubsection{Teilmenge}
$A \subset B:\Leftrightarrow$ wenn alle Elemente von $A$ auch in $B$ sind, dann ist $A$ eine Teilmenge von $B$ oder auch $B$ die Obermenge von $A$.\\
Jede Menge ist Teilmenge von sich selbst. 
\subsubsection{Potenzmenge}
Die Potenzmenge $\mathcal{P}(X)$ ist eine Menge welche aus allen Teilmengen von $U \subseteq X$ besteht.
\subsubsection{Mächtigkeit}
$|A|:=$ Zahl der Elemente von A.
\subsubsection{Vereinigung}
$A\cup B:=$ Menge aus allen Elementen welche in $A$ oder in $B$ oder in beiden enthalten sind.
\subsubsection{Schnitt}
$A\cap B:=$ Menge aus allen Elementen welche in $A$ und in $B$ enthalten sind.
\subsubsection{Differenz}
$A\setminus B:=$ Menge aus allen Elementen welche zu $A$ aber \textbf{nicht} zu $B$ gehören.
\subsubsection{Komplement}
$A^C:=$ Menge aus allen Elementen welche \textbf{nicht} zu $A$ gehören.
\subsubsection{Kartesisches Produkt}
\begin{equation*}
	A \times B:={(a, b):a\in A, b\in B}
\end{equation*}
\subsubsection{$\sigma$-Algebra}
Eine Teilmenge einer Potenzmenge (Menge von Teilmengen, $\mathcal{A}\subseteq\mathcal{P}(\Omega)$) heißt $\sigma$-Algebra wenn sie folgende Bedingungen erfüllt:
\begin{itemize}
	\item Die Teilmenge $\mathcal{A}$ der Potenzmenge $\mathcal{P}(\Omega)$ enthält die Grundmenge $\Omega$.
	\item Das Komplement $A^\mathrm{C}$ eines Elements der Teilmenge $A \in\mathcal{A}$ ist gleich der Differenz aus Grundmenge und Element $A^\mathrm{C} := \Omega\setminus A$. Stabilität des Komplements.
	\item Sind die Mengen in der Teilmenge der Potenzmenge $A_1,A_2,A_3,... \in \mathcal{A}$ enthalten, so ist auch die Vereinigung aller Mengen in der Teilmenge der Potenzmenge enthalten $\bigcup\limits_{n\epsilon \mathbb{N}}A_n \in \mathcal{A}$
	\item Alle vorangegangenen Mengenoperationen können auf die Teilmengen angewendet werden. 
\end{itemize}

\subsection{Zufallsexperiment}
\begin{itemize}
	\item Genau festgelegte Bedingungen
	\item Zufälliger Ausgang
	\item Beliebig oft wiederholbar
	\item Ein Versuch bezeichnet einen Vorgang bei dem mehrere Ergebnisse (Elementarereignis) eintreten können
	\item Menge aller Elementarereignisse wird als Ergebnismenge (Ergebnisraum) $\Omega$ bezeichnet
\end{itemize}
\subsection{Ereignis}
\begin{itemize}
	\item Eine Teilmenge $A \subset \Omega$ heißt Ereignis
	\item $A = \emptyset$ unmögliches Ereignis
	\item $A = \Omega$ sicheres Ereignis
\end{itemize}
\subsubsection{Disjunkte Ereignisse}
Zwei ereignisse sind disjunkt (unvereinbar) wenn deren Schnitt gleich der leeren Menge ist $A \cap B = \emptyset$.
\subsubsection{Unabhängige Ereignisse}
Zwei Ereignisse heißen \textbf{unabhängig} wenn gilt: 
\begin{equation*}
	P(A\cap B) = P(A) \cdot P(B)
\end{equation*}
Sie heißen \textbf{abhängig} wenn sie nicht unabhängig sind.\\
Für unabhängige Ereignisse gilt:
\begin{equation*}
	P(A) = \frac{P(A\cap B)}{P(B)} \text{\quad bzw. \quad} P(B)=\frac{P(A\cap B)}{P(A)}
\end{equation*} 
\subsection{Axiome der Wahrscheinlichkeitsrechnung}
Die Funktion $P$ ordnet jedem Ereignis $A$ eine Wahrscheinlichkeit $P(A)$ zu.
\begin{enumerate}
	\item[(I)] Für jedes Ereignis $A\subset \Omega$ gilt $0\leq P(A) \leq 1$
	\item[(I')] Für das unmögliche Ereignis gilt $P(\emptyset) = 0$
	\item[(II)] Für das sichere Ereignis $\Omega$ gilt $P(\Omega) = 1$
	\item[(II')] Für ein Ereignis $A \subset \Omega$ gilt $P(A^C) = 1- P(A)$
	\item[(III)] Für disjunkte Ereignisse $A$ und $B$ gilt $P(A\cup B) = P(A)+P(B)$ 
	\item[(III')] Für zwei Ereignisse $A,B \subset \Omega$ gilt $P(A\cup B)= P(A)+P(B)-P(A\cap B)$ 
\end{enumerate}
\subsection{Laplace Experiment}
Endlich viele Elementarereignisse welche alle gleich wahrscheinlich sind.\\
Satz von Laplace:
\begin{equation*}
	P(A) = \frac{|A|}{|\Omega|}=\frac{\text{Anzahl der Elementarereignisse in $A$}}{\text{Anzahl aller möglichen Elementarereignisse}}
\end{equation*}
\subsection{Bedingte Wahrscheinlichkeit}
"Wahrscheinlichkeit von A gegeben B".
\begin{equation*}
	P(A|B) := \frac{P(A\cap B)}{P(B)}
\end{equation*}
Sind $A, B \subset \Omega$ \textbf{unabhängige} Ereignisse gilt:
\begin{equation*}
	P(A|B) = P(A)
\end{equation*}
Sind $A, B \subset \Omega$ \textbf{abhängige} Ereignisse gilt:
\begin{equation*}
	P(A|B) \neq P(A)
\end{equation*}
\subsubsection{Multiplikationssatz}
\begin{equation*}
	P(A\cap B) = P(A) \cdot P(B|A) = P(B) \cdot P(A|B)
\end{equation*}
\subsubsection{Satz der totalen Wahrscheinlichkeit}
Der Ergebnisraum ist gegeben durch $\Omega = \bigcup\limits_{j=1}^\infty B_j$ mit $P(B_j)>0$ und alle $j$ sind paarweise Disjunkt $B_i \cap B_j = \emptyset$ für $i\neq j$
\begin{equation*}
	P(A) = \sum_{j=1}^\infty P(A|B_j) \cdot P(B_j)
\end{equation*}
Für den Spezialfall $\Omega = B\cup B^C$ gilt:
\begin{equation*}
	P(A) = P(B) \cdot P(A|B) + P(B^C) \cdot P(A|B^C)
\end{equation*}
\subsubsection{Satz von Bayes}
Besteht aus dem Multiplikationssatz \& der totalen Wahrscheinlichkeit:
\begin{equation*}
	P(A|B)=\frac{P(A)\cdot P(B|A)}{P(B)}= \frac{P(A)\cdot P(B|A)}{P(A)\cdot P(B|A) + P(A^C)\cdot P(B|A^C)}
\end{equation*}
\subsection{Zufallsvariablen}
Eine Zufallsvariable ist eine Abbildung des Ergebnisraums auf den reellen Zahlenraum $\Omega\longmapsto\mathbb{R}$. Die Zufallsvariable ordnet jedem Elementarereignis eine reelle Zahl zu.\\
Zwei Zufallsvariablen sind \textbf{unabhängig} wenn gilt:
\begin{equation*}
	P(X\in A, Y\in B) = P(X\in A) \cdot P(Y\in B) \text{\quad für alle\quad} A,B\subset \mathbb{R} 
\end{equation*}
Die Zufallsvariablen heißen \textbf{abhängig} wenn sie nicht unabhängig sind.
\subsubsection{Diskrete Zufallsvariable}
Die Zufallsvariable wird \textbf{diskret} genannt wenn sie nur endlich viele oder abzählbar unendlich viele Werte annimmt. Es gilt:
\begin{equation*}
	\sum\limits_{i=1}^\infty P(X=x_i)=1
\end{equation*}
\subsubsection{Wahrscheinlichkeitsfunktion}
Für die diskrete Zufallsvariable $X$ und ihre Ausprägungen lautet die Wahrscheinlichkeitsfunktion:
\begin{equation*}
	p_X(x):=
	\begin{cases}
		P(X=x_i) \text{, für } x = x_i \text{ mit Zählindex } i \in \mathbb{N}\\
		0 \text{, sonst}
	\end{cases}
\end{equation*}
\begin{equation*}
	\sum\limits_{x_i}p_X(x_i)=1=p(\Omega)
\end{equation*}
\subsubsection{Verteilungsfunktion diskreter Zufallsvariablen}
Für die diskrete Zufallsvariable $X$ und ihre Ausprägungen lautet die Verteilungsfunktion:
\begin{equation*}
	F_X(x):=P(X\leq x)=\sum_{x_i\leq x}P(X=x_i)=\sum_{x_i\leq x}p_X(x_i)
\end{equation*}
\subsubsection{Stetige Zufallsvariable}
Eine zuvallsvariable wird \textbf{stetig} genannt, wenn es eine nicht-negative Funktion $f_X\geq 0$ mit 
\begin{equation*}
	\int\limits_{-\infty}^\infty f_X(x) dx = 1
\end{equation*}
gibt, so dass für alle $a,b \in \mathbb{R} \cup \{-\infty, \infty\}$ mit $a\leq b$ gilt:
\begin{equation*}
	P(X\in [a,b]) = P(a\leq X \leq b) = \int\limits_a^b f_X(x)dx
\end{equation*}
$f_X$ wird als \textbf{Dichtefunktion} (Wahrscheinlichkeitsdichte) der Zufallsvariable $X$ bezeichnet.
Ihre Verteilungsfunktion $F_X$ lautet:
\begin{equation*}
	F_X(x):=P(X\leq x) = \int\limits_{-\infty}^x f_X(u)du
\end{equation*}
Außerdem gilt:
\begin{equation*}
	f_X = F'_X
\end{equation*}
Daraus folgt:
\begin{equation*}
	P(X\in [a,b]) = P(a\leq X \leq b) = \int\limits_a^b f_X(x)dx = F_X(b) - F_X(a)
\end{equation*}
\subsubsection{Symmetrische Zufallsvariable}
Eine Zufallsvariable $X$ wird \textbf{symmetrisch} genannt, wenn es eine Symmetrieachse $c \in \mathbb{R}$ gibt, so dass für alle $d\in\mathbb{R}$ gilt:
\begin{itemize}
	\item für diskrete Zufallsvariablen 
	\begin{equation*}
		P(X=c-d) = P(X=c+d)
	\end{equation*}
	\item für stetige Zufallsvariablen
	\begin{equation*}
		f_X(c-d)=f_X(c+d)
	\end{equation*}
\end{itemize}
\subsubsection{Mehrdimensionale Verteilungsfunktion}
Die \textbf{Verteilungsfunktion} einer zweidimensionalen Zufallsveriablen $Z = (X_1,...,X_n)$ wird definiert durch:
\begin{equation*}
	F_Z(x_1,...,y)=P(X_1\leq x_1,..., X_n\leq x_n).
\end{equation*}
\subsubsection{Rand-Verteilungsfunktion}
Als Rand-Verteilungsfunktion einer mehrdimensionalen Zufallsvariablen $Z=(X_1,...,X_n)$ wird diejenige Funktion bezeichnet welche lediglich eine dimension betrachtet.
\begin{equation*}
	F_{X_i}(x_i)=F_Z(\infty,...,\infty,x_i,\infty,...,\infty)
\end{equation*}
Für die zweidimensionale Rand-Verteilungsfunktion ($Z=(X,Y)$, $F_Z(x,y)$) gilt:
\begin{equation*}
	F_X(x)=F_Z(x,\infty) \text{ sowie } F_Y(y) = F_Z(\infty,y)
\end{equation*}
\subsubsection{Totale Wahrscheinlichkeit}
\begin{equation*}
	f_X(x) = \int f_{X,Y}(x,y)dy = \int f_Y(y) \cdot f_X(x|Y=y) dy
\end{equation*}
Mit dieser Formel lässt sich eine Rand-Dichte aus einer gemeinsamen Dichte bestimmen, dies wird als \textbf{Marginalisierung} bezeichnet.
\subsubsection{Erwartungswert einer Zufallsvariable}
Für eine diskrete Zufallsvariable mit $(x_i)_{i\in \mathbb{N}}$ Ausprägungen und Wahrscheinlichkeitsfunktion $p_X$ lautet der \textbf{Erwartungswert}:
\begin{equation*}
	E(X):=\sum\limits_{i=1}^\infty x_i\cdot p_X(x_i)
\end{equation*}
Für eine stetige Zufallsvariable mit Dichte $f_X$ lautet der Erwartungswert:
\begin{equation*}
	E(X):=\int\limits_{-\infty}^\infty x\cdot f_X(x) dx
\end{equation*}
\subsubsection{Transformationen von Zufallsvariablen}
\begin{itemize}
	\item Linearität:
	\begin{equation*}
		E(a\cdot X + b\cdot Y)=a\cdot E(X)+b\cdot E(Y)
	\end{equation*}
	\item Multiplikation:
	\begin{equation*}
		E(X\cdot Y) = E(X)\cdot E(Y)
	\end{equation*}
\end{itemize}
\subsubsection{Varianz einer Zufallsvariable}
Eine Zufallsvariable mit Erwartungswert $\mu = E(X)$ hat die \textbf{Varianz}:
\begin{equation*}
	\sigma^2(X):=E[(X-\mu)^2]=E(X^2)-\mu^2
\end{equation*}
Die Standartabweichung lautet:
\begin{equation*}
	\sigma(X) = \sqrt{\sigma^2(X)}
\end{equation*}
\subsubsection{Grenzwertsatz von Zufallsvariablen}
Für $X_1,...,X_n$ unabhängige und identisch verteilte Zufallsvariablen mit $E(X_i)=\mu$, $\sigma(X_i)=\sigma$ und $\overline{X}:=\frac{1}{n}(X_1+...+X_n)$ gilt:
\begin{gather*}
	E(\overline{X})=\mu \\
	\sigma^2(\overline{X})=\frac{\sigma^2}{n}\\
	\sigma(X)=\frac{\sigma}{\sqrt{n}}
\end{gather*}
\subsection{Quantil}
Bezeichnet das kleinste $x$ mit $F_X(x)\geq p$. \\
Spezielle Quantile sind:
\begin{itemize}
	\item $x_{0.5}$ Median
	\item $x_{0.25}, x_{0.5}, x_{0.75}$ erstes, zweites und drittes Quantil
	\item $x_{0.01}, x_{0.02}, x_{0.03}, ...$ erstes, zweites, drittes, ... Perzentil
\end{itemize}
\subsection{Diskrete Verteilungen}
\subsubsection{Bernoulli-Verteilung}
Eine Zufallsvariable wird \textbf{Bernoulli-verteilt} genannt, wenn sie nur zwei mögliche Ausprägungen (z.B. 0 \& 1) hat.  Ihre Wahrscheinlichkeit lautet:
\begin{equation*}
	p:=P(X=1) \text{ und } q:=1-p=P(X=0)
\end{equation*}
Außerdem gilt:
\begin{gather*}
	E(X)=p\\
	\sigma^2(X)=p\cdot q=p\cdot (1-p)\\
	\sigma(X)=\sqrt{p\cdot q}=\sqrt{p\cdot (1-p)}
\end{gather*}
\subsubsection{Binomialverteilung}
Eine \textbf{Binomialverteilung} $X$ bezeichnet die Anzahl der Erfolge bei $n$ identischen unabhängigen Bernoulli-Experimenten $X \sim B(n;p)$.  
\begin{gather*}
	B(n;p)(k) := p_X(k) = P(X=k):= {n \choose k}p^k\cdot (1-p)^{n-k} \text{ für } k=0,1,...,n \\
	 B(n;p)(k) := \frac{n!}{k!\cdot(n-k)!}p^k\cdot (1-p)^{n-k}
\end{gather*}
Weiter gilt:
\begin{gather*}
	E(X)=n\cdot p\\
	\sigma^2(X)=n\cdot p \cdot (1-p)\\
	\sigma(X)=\sqrt{n\cdot p\cdot (1-p)}
\end{gather*}
Eine Binmialverteilung ist für $p=0,0.5,1$ symmetrisch. Für alle anderen Werte ist sie nicht symmetrisch.\\
Aufgrund der Symmetrie gilt zudem:
\begin{equation*}
	B(n;p)(k) = B(n;1-p)(n-k) \text{ mit } n\in \mathbb{N}, p\in [0,1]
\end{equation*}
Für zwei Binominalverteilungen $X\sim B(n_1,p)$ und $Y\sim B(n_2,p)$ gilt, dass deren Summe wieder Binomialverteilt ist:
\begin{equation*}
	X+Y\sim B(n_1+n_2,p)
\end{equation*}
Eine Binomialverteilung $X$ mit seltenen Ereignissen $(p\approx0, N\gg 0)$ wird \textbf{Poissonverteilung} genannt $X\sim Po(\lambda)$. Sie wird approximiert durch:
\begin{equation*}
	p_X(k)=P(X=k):=\frac{\lambda^k}{k!}\cdot e^{-\lambda} \text{ für } k=0,1,2,3,... \text{ und mit } \lambda:=E(X)
\end{equation*}
\subsection{Stetige Verteilungen}
\subsubsection{Gleichverteilung}
Die \textbf{Gleichverteilung} $X$ auf $[a,b]\subset \mathbb{R}$ ($X\sim U([a,b])$) besitzt folgende Dichte:
\begin{equation*}
	f_X(x)=\begin{cases}
		\frac{1}{b-a} \text{, für} x\in [a,b] = \int_a^b\frac{1}{b-a}dx=\frac{b}{b-a}-\frac{a}{b-a}=1\\
		0\text{, sonst}
	\end{cases}
\end{equation*}
Es gilt:
\begin{gather*}
	E(X)=\frac{a+b}{2}\\
	\sigma^2 =\frac{(b-a)^2}{12}\\
	\sigma = \frac{b-a}{\sqrt{12}}
\end{gather*}
\subsubsection{Inversionsmethode}
Es sei $X$ eine Zufallsvariable und $F_X$ ihre Verteilungsfunktion.\\
Die Funktion $F_X^{-1}$ ist die inverse Verteilungsfunktion (\textbf{Quantil-Funktion}):
\begin{equation*}
	F_X^{-1}(u):= \inf\{x\in\mathbb{R}|F(x)\geq u\}
\end{equation*}
Bedeutet, die inverse Verteilungsfunktion liefert das kleinste $x$ welches in der Verteilungsfunktion den Funktionswert $u$ überschreitet.\\
Für eine gleichverteilte Zufallsvariable (das bedeutet alle Zahlen von 0 bis 1 kommen gleich häufig vor) $U\sim U([0,1])$ gilt:
\begin{equation*}
	X:=F_X^{-1}(U) \text{ hat die Verteilungsfunktion } F_X
\end{equation*}
Erklärung: U ist von 0 bis 1 gleichverteilt (alle Zahlen (x-Achse) kommen gleich häufig vor). Nun wird jeder Wert der Zufallsvariable U in die inverse Verteilungsfunktion eingesetzt. Dadurch wird jetzt die Funktion $F_X$ nachgebildet, da immer das kleinste x der Verteilungsfunktion für den Wert von U zurückgegeben wird.
\subsection{Normalverteilung}
Die \textbf{Normalverteilung} $X$ ($X\sim N(\mu , \sigma^2)$) mit den Parametern $\mu\in\mathbb{R}$ und $\sigma\in\mathbb{R}^+$ besitzt folgende Dichte und wird auch \textbf{Gaußsche Glockenkurve} genannt:
\begin{equation*}
	f_X(x)=\frac{1}{\sigma\sqrt{2\pi}}\cdot e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2}
\end{equation*}
Die Gaußsche Glockenkurve besitzt an der Stelle $\mu$ ein Maximum, sowie zwei Wendepunkte an den Stellen $\mu\pm\sigma$. Zudem Gilt:
\begin{gather*}
	E(X)=\mu \\
	\sigma(X)=\sigma
\end{gather*}
Falls $\mu = 0$ und $\sigma = 1$ nennt man die normalverteilte Zufallsgröße $X$ auch Standartnormalfunktion $\Phi$. Für diese gilt:
\begin{gather*}
	\Phi(-z) = 1-\Phi(z) \text{ mit } z\in\mathbb{R}
\end{gather*} 
Falls $Y:=a\cdot X+b$ mit $a,b\in\mathbb{R}$, $a\neq 0$ und $X\sim N(\mu,\sigma^2)$ dann gilt:
\begin{gather*}
	Y\sim N(a\mu+b,a^2\sigma^2)\\
	\frac{X-\mu}{\sigma}\sim N(0,1)
\end{gather*}
Daher gilt weiter:
\begin{gather*}
	P(X\leq x)=\Phi\left(\frac{x-\mu}{\sigma}\right) \text{ mit } x\in\mathbb{R}\\
	P(X\in[a,b])=P(a\leq X\leq b)=\Phi\left(\frac{b-\mu}{\sigma}\right)-\Phi\left(\frac{a-\mu}{\sigma}\right) \text{ mit } a,b\in\mathbb{R} \text{ und } a<b
\end{gather*}
Für eine Normalverteilung $X\sim N(\mu,\sigma^2)$ mit $\alpha\in\mathbb{R}^+$ gilt:
\begin{equation*}
	P(\mu-\alpha<X<\mu+\alpha)=2\Phi\left(\frac{\alpha}{\sigma}\right)-1
\end{equation*}
Wenn nun $p\in[0,1]$ liegt und $\overline{x}$ mit $\Phi(\overline{x})=\frac{p+1}{2}$ ist, so gilt mit $\alpha=\sigma\cdot\overline{x}$:
\begin{equation*}
	P(\mu-\alpha<X\mu+\alpha)=p
\end{equation*}
Daher gilt, dass
\begin{itemize}
	\item $P(\mu-\sigma\leq X\leq\mu+\sigma)\approx\frac{2}{3}$
	\item $P(\mu-2\sigma\leq X\leq\mu+2\sigma)\approx 0.95$
	\item $P(\mu-3\sigma\leq X\leq\mu+3\sigma)\approx 0.9975$
\end{itemize}
\section{Zusatz}
\subsection{Integration}
\begin{equation*}
	\int\limits_{a}^{b}f(x) dx = [F(x)]_a^b = F(b) - F(a)
\end{equation*}
\begin{equation*}
	\int\limits_{a}^{b}f(x) + g(x) dx = \int\limits_{a}^{b}f(x) dx + \int\limits_{a}^{b}g(x) dx
\end{equation*}
\begin{equation*}
	\int\limits_{a}^{b}c\cdot f(x) dx = c\cdot \int\limits_{a}^{b}f(x) dx
\end{equation*}
\subsection{Partielle Integration}
\begin{equation*}
	u(x)\cdot v(x) = \int u'(x) \cdot v(x) dx + \int u(x) \cdot v'(x) dx
\end{equation*}
\todo{Integrations regeln}
\subsection{Differentialgleichungen}
\todo{Basics DGL Lösungen}
\newpage
\subsection{Standartnormalverteilungstabelle}
\begin{table}[H]
	\begin{adjustbox}{width=\columnwidth,center}
	\begin{tabular}{|>{\bfseries}x|l|l|l|l|l|l|l|l|l|l|}
	\hline
	\rowcolor{LightCyan}
		z & \textbf{0} & \textbf{0,01} & \textbf{0,02} & \textbf{0,03} & \textbf{0,04} & \textbf{0,05} & \textbf{0,06} & \textbf{0,07} & \textbf{0,08} & \textbf{0,09}\\\hline
	0,0 & 0,50000 & 0,50399 & 0,50798 & 0,51197 & 0,51595 & 0,51994 & 0,52392 & 0,52790 & 0,53188 & 0,53586\\\hline\rowcolor{Gray}
	\cellcolor{LightCyan}0,1 & 0,53983 & 0,54380 & 0,54776 & 0,55172 & 0,55567 & 0,55962 & 0,56356 & 0,56749 & 0,57142 & 0,57535\\\hline
	0,2 & 0,57926 & 0,58317 & 0,58706 & 0,59095 & 0,59483 & 0,59871 & 0,60257 & 0,60642 & 0,61026 & 0,61409\\\hline\rowcolor{Gray}
	\cellcolor{LightCyan}0,3 & 0,61791 & 0,62172 & 0,62552 & 0,62930 & 0,63307 & 0,63683 & 0,64058 & 0,64431 & 0,64803 & 0,65173\\\hline
	0,4 & 0,65542 & 0,65910 & 0,66276 & 0,66640 & 0,67003 & 0,67364 & 0,67724 & 0,68082 & 0,68439 & 0,68793\\\hline\rowcolor{Gray}
	\cellcolor{LightCyan}0,5 & 0,69146 & 0,69497 & 0,69847 & 0,70194 & 0,70540 & 0,70884 & 0,71226 & 0,71566 & 0,71904 & 0,72240\\\hline
	0,6 & 0,72575 & 0,72907 & 0,73237 & 0,73565 & 0,73891 & 0,74215 & 0,74537 & 0,74857 & 0,75175 & 0,75490\\\hline\rowcolor{Gray}
	\cellcolor{LightCyan}0,7 & 0,75804 & 0,76115 & 0,76424 & 0,76730 & 0,77035 & 0,77337 & 0,77637 & 0,77935 & 0,78230 & 0,78524\\\hline
	0,8 & 0,78814 & 0,79103 & 0,79389 & 0,79673 & 0,79955 & 0,80234 & 0,80511 & 0,80785 & 0,81057 & 0,81327\\\hline\rowcolor{Gray}
	\cellcolor{LightCyan}0,9 & 0,81594 & 0,81859 & 0,82121 & 0,82381 & 0,82639 & 0,82894 & 0,83147 & 0,83398 & 0,83646 & 0,83891\\\hline
	1,0 & 0,84134 & 0,84375 & 0,84614 & 0,84849 & 0,85083 & 0,85314 & 0,85543 & 0,85769 & 0,85993 & 0,86214\\\hline\rowcolor{Gray}
	\cellcolor{LightCyan}1,1 & 0,86433 & 0,86650 & 0,86864 & 0,87076 & 0,87286 & 0,87493 & 0,87698 & 0,87900 & 0,88100 & 0,88298\\\hline
	1,2 & 0,88493 & 0,88686 & 0,88877 & 0,89065 & 0,89251 & 0,89435 & 0,89617 & 0,89796 & 0,89973 & 0,90147\\\hline\rowcolor{Gray}
	\cellcolor{LightCyan}1,3 & 0,90320 & 0,90490 & 0,90658 & 0,90824 & 0,90988 & 0,91149 & 0,91309 & 0,91466 & 0,91621 & 0,91774\\\hline
	1,4 & 0,91924 & 0,92073 & 0,92220 & 0,92364 & 0,92507 & 0,92647 & 0,92785 & 0,92922 & 0,93056 & 0,93189\\\hline\rowcolor{Gray}
	\cellcolor{LightCyan}1,5 & 0,93319 & 0,93448 & 0,93574 & 0,93699 & 0,93822 & 0,93943 & 0,94062 & 0,94179 & 0,94295 & 0,94408\\\hline
	1,6 & 0,94520 & 0,94630 & 0,94738 & 0,94845 & 0,94950 & 0,95053 & 0,95154 & 0,95254 & 0,95352 & 0,95449\\\hline\rowcolor{Gray}
	\cellcolor{LightCyan}1,7 & 0,95543 & 0,95637 & 0,95728 & 0,95818 & 0,95907 & 0,95994 & 0,96080 & 0,96164 & 0,96246 & 0,96327\\\hline
	1,8 & 0,96407 & 0,96485 & 0,96562 & 0,96638 & 0,96712 & 0,96784 & 0,96856 & 0,96926 & 0,96995 & 0,97062\\\hline\rowcolor{Gray}
	\cellcolor{LightCyan}1,9 & 0,97128 & 0,97193 & 0,97257 & 0,97320 & 0,97381 & 0,97441 & 0,97500 & 0,97558 & 0,97615 & 0,97670\\\hline
	2,0 & 0,97725 & 0,97778 & 0,97831 & 0,97882 & 0,97932 & 0,97982 & 0,98030 & 0,98077 & 0,98124 & 0,98169\\\hline\rowcolor{Gray}
	\cellcolor{LightCyan}2,1 & 0,98214 & 0,98257 & 0,98300 & 0,98341 & 0,98382 & 0,98422 & 0,98461 & 0,98500 & 0,98537 & 0,98574\\\hline
	2,2 & 0,98610 & 0,98645 & 0,98679 & 0,98713 & 0,98745 & 0,98778 & 0,98809 & 0,98840 & 0,98870 & 0,98899\\\hline\rowcolor{Gray}
	\cellcolor{LightCyan}2,3 & 0,98928 & 0,98956 & 0,98983 & 0,99010 & 0,99036 & 0,99061 & 0,99086 & 0,99111 & 0,99134 & 0,99158\\\hline
	2,4 & 0,99180 & 0,99202 & 0,99224 & 0,99245 & 0,99266 & 0,99286 & 0,99305 & 0,99324 & 0,99343 & 0,99361\\\hline\rowcolor{Gray}
	\cellcolor{LightCyan}2,5 & 0,99379 & 0,99396 & 0,99413 & 0,99430 & 0,99446 & 0,99461 & 0,99477 & 0,99492 & 0,99506 & 0,99520\\\hline
	2,6 & 0,99534 & 0,99547 & 0,99560 & 0,99573 & 0,99585 & 0,99598 & 0,99609 & 0,99621 & 0,99632 & 0,99643\\\hline\rowcolor{Gray}
	\cellcolor{LightCyan}2,7 & 0,99653 & 0,99664 & 0,99674 & 0,99683 & 0,99693 & 0,99702 & 0,99711 & 0,99720 & 0,99728 & 0,99736\\\hline
	2,8 & 0,99744 & 0,99752 & 0,99760 & 0,99767 & 0,99774 & 0,99781 & 0,99788 & 0,99795 & 0,99801 & 0,99807\\\hline\rowcolor{Gray}
	\cellcolor{LightCyan}2,9 & 0,99813 & 0,99819 & 0,99825 & 0,99831 & 0,99836 & 0,99841 & 0,99846 & 0,99851 & 0,99856 & 0,99861\\\hline
	3,0 & 0,99865 & 0,99869 & 0,99874 & 0,99878 & 0,99882 & 0,99886 & 0,99889 & 0,99893 & 0,99896 & 0,99900\\\hline\rowcolor{Gray}
	\cellcolor{LightCyan}3,1 & 0,99903 & 0,99906 & 0,99910 & 0,99913 & 0,99916 & 0,99918 & 0,99921 & 0,99924 & 0,99926 & 0,99929\\\hline
	3,2 & 0,99931 & 0,99934 & 0,99936 & 0,99938 & 0,99940 & 0,99942 & 0,99944 & 0,99946 & 0,99948 & 0,99950\\\hline\rowcolor{Gray}
	\cellcolor{LightCyan}3,3 & 0,99952 & 0,99953 & 0,99955 & 0,99957 & 0,99958 & 0,99960 & 0,99961 & 0,99962 & 0,99964 & 0,99965\\\hline
	3,4 & 0,99966 & 0,99968 & 0,99969 & 0,99970 & 0,99971 & 0,99972 & 0,99973 & 0,99974 & 0,99975 & 0,99976\\\hline\rowcolor{Gray}
	\cellcolor{LightCyan}3,5 & 0,99977 & 0,99978 & 0,99978 & 0,99979 & 0,99980 & 0,99981 & 0,99981 & 0,99982 & 0,99983 & 0,99983\\\hline
	3,6 & 0,99984 & 0,99985 & 0,99985 & 0,99986 & 0,99986 & 0,99987 & 0,99987 & 0,99988 & 0,99988 & 0,99989\\\hline\rowcolor{Gray}
	\cellcolor{LightCyan}3,7 & 0,99989 & 0,99990 & 0,99990 & 0,99990 & 0,99991 & 0,99991 & 0,99992 & 0,99992 & 0,99992 & 0,99992\\\hline
	3,8 & 0,99993 & 0,99993 & 0,99993 & 0,99994 & 0,99994 & 0,99994 & 0,99994 & 0,99995 & 0,99995 & 0,99995\\\hline\rowcolor{Gray}
	\cellcolor{LightCyan}3,9 & 0,99995 & 0,99995 & 0,99996 & 0,99996 & 0,99996 & 0,99996 & 0,99996 & 0,99996 & 0,99997 & 0,99997\\\hline
	4,0 & 0,99997 & 0,99997 & 0,99997 & 0,99997 & 0,99997 & 0,99997 & 0,99998 & 0,99998 & 0,99998 & 0,99998\\\hline
	\end{tabular}
	\end{adjustbox}
\end{table}
\newpage
\pagenumbering{Alph}
\section{Anhang}
\printbibliography[heading=subbibnumbered]
\end{document}